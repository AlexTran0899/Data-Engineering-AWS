{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce\n",
    "\n",
    "The MapReduce programming technique was designed to analyze massive data sets across a cluster. In this Jupyter notebook, you'll get a sense for how Hadoop MapReduce works; however, this notebook will run locally rather than on a cluster.\n",
    "\n",
    "The biggest difference between Hadoop and Spark is that Spark tries to do as many calculations as possible in memory, which avoids moving data back and forth across a cluster. Hadoop writes intermediate calculations out to disk, which can be less efficient. Hadoop is an older technology than Spark and one of the cornerstone big data technologies.\n",
    "\n",
    "If you click on the Jupyter notebook logo at the top of the workspace, you'll be taken to the workspace directory. There you will see a file called \"songplays.txt\". This is a text file where each line represents a song that was played in the Sparkify app. The MapReduce code will count how many times each song was played. In other words, the code counts how many times the song title appears in the list.\n",
    "\n",
    "\n",
    "# MapReduce versus Hadoop MapReduce\n",
    "\n",
    "Don't get confused by the terminology! MapReduce is a programming technique. Hadoop MapReduce is a specific implementation of the programming technique.\n",
    "\n",
    "Some of the syntax will look a bit funny, so be sure to read the explanation and comments for each section. You'll learn more about the syntax in later lessons. \n",
    "\n",
    "Run each of the code cells below to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mrjob in /Users/at/.local/share/virtualenvs/udacity-7oez_sss/lib/python3.13/site-packages (0.7.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/at/.local/share/virtualenvs/udacity-7oez_sss/lib/python3.13/site-packages (from mrjob) (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install mrjob library. This package is for running MapReduce jobs with Python\n",
    "# In Jupyter notebooks, \"!\" runs terminal commands from inside notebooks \n",
    "\n",
    "! pip install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '--f=/Users/at/Library/Jupyter/runtime/kernel-v3d1bad0492030ad807432f1d05bcbf3345b827d36.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUsage: python wordcount.py songs.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     sys.exit(\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     34\u001b[39m     lines = f.readlines()\n\u001b[32m     36\u001b[39m job = MRSongCount()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/udacity-7oez_sss/lib/python3.13/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '--f=/Users/at/Library/Jupyter/runtime/kernel-v3d1bad0492030ad807432f1d05bcbf3345b827d36.json'"
     ]
    }
   ],
   "source": [
    "%%file wordcount.py\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "class MRSongCount:\n",
    "    def mapper(self, _, song):\n",
    "        yield (song.strip(), 1)\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "\n",
    "    def run(self, lines):\n",
    "        # MAP\n",
    "        mapped = []\n",
    "        for i, line in enumerate(lines):\n",
    "            for pair in self.mapper(i, line):\n",
    "                mapped.append(pair)\n",
    "\n",
    "        # SHUFFLE & SORT\n",
    "        grouped = defaultdict(list)\n",
    "        for key, value in mapped:\n",
    "            grouped[key].append(value)\n",
    "\n",
    "        # REDUCE\n",
    "        for key, values in grouped.items():\n",
    "            for result in self.reducer(key, values):\n",
    "                print(f\"{result[0]}\\t{result[1]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python wordcount.py songs.txt\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(sys.argv[1], \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    job = MRSongCount()\n",
    "    job.run(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/at/Documents/udacity/learning/spark-datalake/wordcount.py\"\u001b[0m, line \u001b[35m3\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1;31mfrom mrjob.job import MRJob\u001b[0m # import the mrjob library\n",
      "    \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/at/.local/share/virtualenvs/udacity-7oez_sss/lib/python3.13/site-packages/mrjob/job.py\"\u001b[0m, line \u001b[35m36\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from mrjob.conf import combine_dicts\n",
      "  File \u001b[35m\"/Users/at/.local/share/virtualenvs/udacity-7oez_sss/lib/python3.13/site-packages/mrjob/conf.py\"\u001b[0m, line \u001b[35m34\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from mrjob.util import expand_path\n",
      "  File \u001b[35m\"/Users/at/.local/share/virtualenvs/udacity-7oez_sss/lib/python3.13/site-packages/mrjob/util.py\"\u001b[0m, line \u001b[35m23\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    import pipes\n",
      "\u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'pipes'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# run the code as a terminal command\n",
    "! python wordcount.py songplays.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of what happens in the code.\n",
    "\n",
    "There is a list of songs in songplays.txt that looks like the following:\n",
    "\n",
    "Deep Dreams\n",
    "Data House Rock\n",
    "Deep Dreams\n",
    "Data House Rock\n",
    "Broken Networks\n",
    "Data House Rock\n",
    "etc.....\n",
    "\n",
    "During the map step, the code reads in the txt file one line at a time. The map steps outputs a set of tuples that look like this:\n",
    "\n",
    "(Deep Dreams, 1)  \n",
    "(Data House Rock, 1)  \n",
    "(Deep Dreams, 1)  \n",
    "(Data House Rock, 1)  \n",
    "(Broken Networks, 1)  \n",
    "(Data House Rock, 1)  \n",
    "etc.....\n",
    "\n",
    "Finally, the reduce step combines all of the values by keys and sums the values:  \n",
    "\n",
    "(Deep Dreams, \\[1, 1, 1, 1, 1, 1, ... \\])  \n",
    "(Data House Rock, \\[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\\])  \n",
    "(Broken Networks, \\[1, 1, 1, ...\\]  \n",
    "\n",
    "With the output \n",
    "\n",
    "(Deep Dreams, 1131)  \n",
    "(Data House Rock, 510)  \n",
    "(Broken Networks, 828)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity-7oez_sss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
